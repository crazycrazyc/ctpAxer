#!/usr/bin/env python3
"""
æ”¯æŒWebSocketçš„Flaskåº”ç”¨
é›†æˆå®æ—¶è¡Œæƒ…åˆ†å‘åŠŸèƒ½
"""

from flask import Flask, render_template, request, jsonify, send_file, make_response
from flask_socketio import SocketIO, emit, join_room, leave_room
import mysql.connector
from mysql.connector import Error
import pandas as pd
import io
import csv
from datetime import datetime
import os
import redis
import json
import threading
import traceback
import time
from contextlib import contextmanager
import queue  # æ·»åŠ é˜Ÿåˆ—æ”¯æŒ

# å¤åˆ¶åŸæœ‰çš„æ•°æ®åº“é…ç½®å’Œç®¡ç†å™¨
DB_CONFIG = {
    'host': '172.16.30.97',
    'port': 13306,
    'user': 'elwriter',
    'password': 'elwriter123',
    'database': 'cta_trade',
    'charset': 'utf8mb4'
}

import threading
from contextlib import contextmanager

class DatabaseManager:
    def __init__(self):
        self.max_retries = 3
        self.retry_delay = 0.5
        self._local = threading.local()
        self._lock = threading.Lock()
    
    @contextmanager
    def get_db_connection(self):
        connection = None
        try:
            connection = mysql.connector.connect(
                **DB_CONFIG,
                autocommit=True,
                use_pure=True,
                connection_timeout=5,
                sql_mode='TRADITIONAL'
            )
            yield connection
        except Error as e:
            print(f"æ•°æ®åº“è¿æ¥åˆ›å»ºå¤±è´¥: {e}")
            raise
        finally:
            if connection and connection.is_connected():
                try:
                    connection.close()
                except:
                    pass
    
    def execute_query(self, query, params=None):
        last_error = None
        for attempt in range(self.max_retries):
            try:
                with self.get_db_connection() as connection:
                    cursor = connection.cursor(dictionary=True)
                    cursor.execute(query, params)
                    result = cursor.fetchall()
                    cursor.close()
                    return result
            except Error as e:
                last_error = e
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay * (attempt + 1))
                    continue
            except Exception as e:
                last_error = e
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
        print(f"æ•°æ®åº“æŸ¥è¯¢æœ€ç»ˆå¤±è´¥: {query}, æœ€åé”™è¯¯: {last_error}")
        return None
    
    def connect(self):
        return True
    
    def disconnect(self):
        pass

# åˆå§‹åŒ–
app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'

# åˆå§‹åŒ–SocketIO
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='eventlet')

# æ•°æ®åº“ç®¡ç†å™¨
db_manager = DatabaseManager()

# Redisè¿æ¥
redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)

# å…¨å±€å˜é‡
market_subscribers = set()  # å­˜å‚¨è®¢é˜…è¡Œæƒ…çš„å®¢æˆ·ç«¯
market_thread = None
market_running = False

# æ·»åŠ è°ƒè¯•å˜é‡
client_debug_info = {}  # å­˜å‚¨å®¢æˆ·ç«¯è°ƒè¯•ä¿¡æ¯
connection_count = 0    # è¿æ¥è®¡æ•°å™¨

# æœ€æ–°è¡Œæƒ…æ•°æ®å­˜å‚¨
latest_market_data = {}  # å­˜å‚¨æœ€æ–°çš„è¡Œæƒ…æ•°æ®ï¼ŒæŒ‰åˆçº¦IDç´¢å¼•
send_batch_offset = 0    # å‘é€æ‰¹æ¬¡åç§»é‡ï¼Œç”¨äºè½®æ¢å‘é€

# ========== åŸæœ‰çš„è·¯ç”±ï¼ˆåŸapp.pyåŠŸèƒ½å·²æ•´åˆï¼‰ ==========

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/accounts')
def accounts():
    return render_template('accounts.html')

@app.route('/positions')  
def positions():
    return render_template('positions.html')

@app.route('/realtime')
def realtime():
    """å®æ—¶è¡Œæƒ…é¡µé¢"""
    return render_template('realtime.html')

@app.route('/test_simple')
def test_simple():
    return render_template('test_simple.html')

# åŸæœ‰çš„APIè·¯ç”±ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
# ========== åˆçº¦ä¿¡æ¯æŸ¥è¯¢API ==========
@app.route('/api/instruments')
def get_instruments():
    page = request.args.get('page', 1, type=int)
    per_page = request.args.get('per_page', 20, type=int)
    search = request.args.get('search', '', type=str)
    
    where_conditions = []
    params = []
    
    if search:
        where_conditions.append("(InstrumentID LIKE %s OR InstrumentName LIKE %s OR ExchangeID LIKE %s)")
        search_param = f"%{search}%"
        params.extend([search_param, search_param, search_param])
    
    where_clause = ""
    if where_conditions:
        where_clause = "WHERE " + " AND ".join(where_conditions)
    
    count_query = f"SELECT COUNT(*) as total FROM test_update_instrument {where_clause}"
    count_result = db_manager.execute_query(count_query, params)
    total = count_result[0]['total'] if count_result else 0
    
    offset = (page - 1) * per_page
    data_query = f"""
        SELECT InstrumentID, InstrumentName, ExchangeID, ProductID, VolumeMultiple, 
               PriceTick, CreateDate, ExpireDate, IsTrading
        FROM test_update_instrument 
        {where_clause}
        ORDER BY InstrumentID 
        LIMIT %s OFFSET %s
    """
    
    params.extend([per_page, offset])
    instruments = db_manager.execute_query(data_query, params)
    
    return jsonify({
        'data': instruments or [],
        'total': total,
        'page': page,
        'per_page': per_page,
        'pages': (total + per_page - 1) // per_page
    })

@app.route('/api/stats')
def get_stats():
    try:
        stats_queries = {
            'total_instruments': "SELECT COUNT(*) as count FROM test_update_instrument",
            'active_instruments': "SELECT COUNT(*) as count FROM test_update_instrument WHERE IsTrading = 1",
            'exchanges': "SELECT ExchangeID, COUNT(*) as count FROM test_update_instrument GROUP BY ExchangeID ORDER BY count DESC",
            'product_classes': "SELECT ProductClass, COUNT(*) as count FROM test_update_instrument GROUP BY ProductClass ORDER BY count DESC"
        }
        
        stats = {}
        for key, query in stats_queries.items():
            result = db_manager.execute_query(query)
            if result is not None:
                stats[key] = result
            else:
                stats[key] = []
        
        return jsonify({
            'status': 'success',
            'data': stats
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': 'ç»Ÿè®¡ä¿¡æ¯è·å–å¤±è´¥',
            'error': str(e)
        }), 500

# ========== å·¥å…·å’Œè°ƒè¯•API ==========

@app.route('/api/instrument/<instrument_id>')
def get_instrument_detail(instrument_id):
    """è·å–ç‰¹å®šåˆçº¦è¯¦ç»†ä¿¡æ¯"""
    query = "SELECT * FROM test_update_instrument WHERE InstrumentID = %s"
    result = db_manager.execute_query(query, [instrument_id])
    
    if result:
        return jsonify({'success': True, 'data': result[0]})
    else:
        return jsonify({'success': False, 'message': 'åˆçº¦ä¸å­˜åœ¨'})

@app.route('/api/export/csv')
def export_csv():
    """å¯¼å‡ºCSVæ–‡ä»¶"""
    search = request.args.get('search', '', type=str)
    instrument_ids = request.args.get('instruments', '', type=str)
    
    # æ„å»ºæŸ¥è¯¢æ¡ä»¶
    where_clause = ""
    params = []
    
    if instrument_ids:
        # æŒ‡å®šåˆçº¦ä»£ç 
        ids = [id.strip() for id in instrument_ids.split(',') if id.strip()]
        if ids:
            placeholders = ','.join(['%s'] * len(ids))
            where_clause = f"WHERE InstrumentID IN ({placeholders})"
            params = ids
    elif search:
        # æœç´¢æ¡ä»¶
        where_clause = "WHERE InstrumentID LIKE %s OR InstrumentName LIKE %s OR ExchangeID LIKE %s"
        search_param = f"%{search}%"
        params = [search_param, search_param, search_param]
    
    # æŸ¥è¯¢æ•°æ®
    query = f"SELECT * FROM test_update_instrument {where_clause} ORDER BY InstrumentID"
    instruments = db_manager.execute_query(query, params)
    
    if not instruments:
        return jsonify({'success': False, 'message': 'æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ•°æ®'})
    
    # åˆ›å»ºCSVæ–‡ä»¶
    output = io.StringIO()
    writer = csv.writer(output, quoting=csv.QUOTE_ALL)
    
    # å†™å…¥è¡¨å¤´
    if instruments:
        headers = list(instruments[0].keys())
        writer.writerow(headers)
        
        # å†™å…¥æ•°æ®
        for instrument in instruments:
            writer.writerow([str(instrument[key]) if instrument[key] is not None else '' for key in headers])
    
    # åˆ›å»ºå“åº”
    output.seek(0)
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f'instruments_{timestamp}.csv'
    
    # åˆ›å»ºå“åº”å¯¹è±¡
    response = make_response(output.getvalue())
    response.headers['Content-Type'] = 'text/csv; charset=utf-8-sig'  # æ·»åŠ BOMä»¥æ”¯æŒä¸­æ–‡
    response.headers['Content-Disposition'] = f'attachment; filename={filename}'
    
    return response

@app.route('/api/health/db')
def check_db_health():
    """æ•°æ®åº“è¿æ¥å¥åº·æ£€æŸ¥"""
    try:
        # æµ‹è¯•ç®€å•æŸ¥è¯¢
        result = db_manager.execute_query("SELECT 1 as test")
        
        if result is not None:
            return jsonify({
                'status': 'healthy',
                'message': 'æ•°æ®åº“è¿æ¥æ­£å¸¸',
                'timestamp': datetime.now().isoformat()
            })
        else:
            return jsonify({
                'status': 'unhealthy',
                'message': 'æ•°æ®åº“æŸ¥è¯¢å¤±è´¥',
                'timestamp': datetime.now().isoformat()
            }), 503
            
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'æ•°æ®åº“è¿æ¥å¼‚å¸¸: {str(e)}',
            'timestamp': datetime.now().isoformat()
        }), 503

@app.route('/api/debug/tables')  
def check_tables():
    """æ£€æŸ¥æ•°æ®åº“è¡¨æ˜¯å¦å­˜åœ¨"""
    try:
        tables_to_check = [
            'test_update_instrument',
            'instruments', 
            'investor_positions',
            'trading_account'
        ]
        
        table_status = {}
        for table in tables_to_check:
            try:
                result = db_manager.execute_query(f"SELECT COUNT(*) as count FROM {table} LIMIT 1")
                if result is not None:
                    table_status[table] = {
                        'exists': True,
                        'count': result[0]['count'] if result else 0
                    }
                else:
                    table_status[table] = {
                        'exists': False,
                        'error': 'æŸ¥è¯¢å¤±è´¥'
                    }
            except Exception as e:
                table_status[table] = {
                    'exists': False,
                    'error': str(e)
                }
        
        return jsonify({
            'status': 'success',
            'tables': table_status,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

# ========== æŒä»“å’Œèµ„é‡‘æŸ¥è¯¢API ==========

@app.route('/api/accounts')
def get_trading_accounts():
    """è·å–èµ„é‡‘è´¦æˆ·åˆ—è¡¨API"""
    page = request.args.get('page', 1, type=int)
    per_page = request.args.get('per_page', 20, type=int)
    search = request.args.get('search', '', type=str)
    
    # æ„å»ºæŸ¥è¯¢æ¡ä»¶
    where_conditions = []
    params = []
    
    if search:
        where_conditions.append("(AccountID LIKE %s OR BrokerID LIKE %s)")
        search_param = f"%{search}%"
        params.extend([search_param, search_param])
    
    where_clause = ""
    if where_conditions:
        where_clause = "WHERE " + " AND ".join(where_conditions)
    
    # è·å–æ€»æ•°
    count_query = f"SELECT COUNT(*) as total FROM trading_account {where_clause}"
    count_result = db_manager.execute_query(count_query, params)
    total = count_result[0]['total'] if count_result else 0
    
    # è·å–åˆ†é¡µæ•°æ®
    offset = (page - 1) * per_page
    data_query = f"""
        SELECT BrokerID, AccountID, Balance, Available, CurrMargin, PositionProfit,
               CloseProfit, FrozenMargin, FrozenCash, TradingDay, PreBalance,
               Deposit, Withdraw, WithdrawQuota, Commission
        FROM trading_account 
        {where_clause}
        ORDER BY TradingDay DESC, AccountID 
        LIMIT %s OFFSET %s
    """
    
    query_params = params + [per_page, offset]
    accounts = db_manager.execute_query(data_query, query_params)
    
    return jsonify({
        'data': accounts or [],
        'total': total,
        'page': page,
        'per_page': per_page,
        'pages': (total + per_page - 1) // per_page
    })

@app.route('/api/account/<account_id>')
def get_account_detail(account_id):
    """è·å–ç‰¹å®šè´¦æˆ·è¯¦ç»†ä¿¡æ¯"""
    query = """
        SELECT * FROM trading_account 
        WHERE AccountID = %s 
        ORDER BY TradingDay DESC 
        LIMIT 1
    """
    result = db_manager.execute_query(query, [account_id])
    
    if result:
        return jsonify({'success': True, 'data': result[0]})
    else:
        return jsonify({'success': False, 'message': 'è´¦æˆ·è®°å½•ä¸å­˜åœ¨'})

@app.route('/api/account/history/<account_id>')
def get_account_history(account_id):
    """è·å–è´¦æˆ·å†å²è®°å½•"""
    query = """
        SELECT * FROM trading_account 
        WHERE AccountID = %s 
        ORDER BY TradingDay DESC 
        LIMIT 30
    """
    result = db_manager.execute_query(query, [account_id])
    
    if result:
        return jsonify({'success': True, 'data': result})
    else:
        return jsonify({'success': False, 'message': 'æ²¡æœ‰æ‰¾åˆ°å†å²è®°å½•'})

@app.route('/api/accounts/summary')
def get_accounts_summary():
    """è·å–è´¦æˆ·æ±‡æ€»ä¿¡æ¯"""
    query = """
        SELECT 
            COUNT(DISTINCT AccountID) as total_accounts,
            SUM(Balance) as total_balance,
            SUM(Available) as total_available,
            SUM(CurrMargin) as total_margin,
            SUM(PositionProfit) as total_position_profit,
            SUM(CloseProfit) as total_close_profit
        FROM trading_account 
        WHERE TradingDay = (SELECT MAX(TradingDay) FROM trading_account)
    """
    result = db_manager.execute_query(query)
    
    if result:
        return jsonify({'success': True, 'data': result[0]})
    else:
        return jsonify({'success': False, 'message': 'æ— æ³•è·å–æ±‡æ€»ä¿¡æ¯'})

@app.route('/api/positions')
def get_positions():
    """è·å–æŒä»“åˆ—è¡¨API"""
    page = request.args.get('page', 1, type=int)
    per_page = request.args.get('per_page', 20, type=int)
    search = request.args.get('search', '', type=str)
    investor_id = request.args.get('investor_id', '', type=str)
    broker_id = request.args.get('broker_id', '', type=str)
    
    # æ„å»ºæŸ¥è¯¢æ¡ä»¶
    where_conditions = []
    params = []
    
    if investor_id:
        where_conditions.append("InvestorID LIKE %s")
        params.append(f"%{investor_id}%")
    
    if broker_id:
        where_conditions.append("BrokerID LIKE %s")
        params.append(f"%{broker_id}%")
    
    if search:
        where_conditions.append("(InstrumentID LIKE %s OR InvestorID LIKE %s OR BrokerID LIKE %s)")
        search_param = f"%{search}%"
        params.extend([search_param, search_param, search_param])
    
    where_clause = ""
    if where_conditions:
        where_clause = "WHERE " + " AND ".join(where_conditions)
    
    # è·å–æ€»æ•°
    count_query = f"SELECT COUNT(*) as total FROM investor_positions {where_clause}"
    count_result = db_manager.execute_query(count_query, params)
    total = count_result[0]['total'] if count_result else 0
    
    # è·å–åˆ†é¡µæ•°æ®
    offset = (page - 1) * per_page
    data_query = f"""
        SELECT InstrumentID, BrokerID, InvestorID, PosiDirection, HedgeFlag,
               YdPosition, Position, PositionProfit, UseMargin, PositionCost,
               OpenCost, Commission, CloseProfit, TradingDay
        FROM investor_positions 
        {where_clause}
        ORDER BY InvestorID, InstrumentID 
        LIMIT %s OFFSET %s
    """
    
    query_params = params + [per_page, offset]
    positions = db_manager.execute_query(data_query, query_params)
    
    return jsonify({
        'data': positions or [],
        'total': total,
        'page': page,
        'per_page': per_page,
        'pages': (total + per_page - 1) // per_page
    })

@app.route('/api/position/<position_id>')
def get_position_detail(position_id):
    """è·å–ç‰¹å®šæŒä»“è¯¦ç»†ä¿¡æ¯"""
    query = "SELECT * FROM investor_positions WHERE id = %s"
    result = db_manager.execute_query(query, [position_id])
    
    if result:
        return jsonify({'success': True, 'data': result[0]})
    else:
        return jsonify({'success': False, 'message': 'æŒä»“è®°å½•ä¸å­˜åœ¨'})

@app.route('/api/investors')
def get_investors():
    """è·å–æŠ•èµ„è€…è´¦æˆ·åˆ—è¡¨"""
    query = "SELECT DISTINCT InvestorID, BrokerID FROM investor_positions ORDER BY InvestorID"
    result = db_manager.execute_query(query)
    
    if result:
        return jsonify({'success': True, 'data': result})
    else:
        return jsonify({'success': False, 'message': 'æ²¡æœ‰æ‰¾åˆ°æŠ•èµ„è€…ä¿¡æ¯'})

@app.route('/api/export/positions/csv')
def export_positions_csv():
    """å¯¼å‡ºæŒä»“æ•°æ®ä¸ºCSV"""
    search = request.args.get('search', '', type=str)
    investor_id = request.args.get('investor_id', '', type=str)
    broker_id = request.args.get('broker_id', '', type=str)
    
    # æ„å»ºæŸ¥è¯¢æ¡ä»¶
    where_conditions = []
    params = []
    
    if investor_id:
        where_conditions.append("InvestorID LIKE %s")
        params.append(f"%{investor_id}%")
    
    if broker_id:
        where_conditions.append("BrokerID LIKE %s")
        params.append(f"%{broker_id}%")
    
    if search:
        where_conditions.append("(InstrumentID LIKE %s OR InvestorID LIKE %s OR BrokerID LIKE %s)")
        search_param = f"%{search}%"
        params.extend([search_param, search_param, search_param])
    
    where_clause = ""
    if where_conditions:
        where_clause = "WHERE " + " AND ".join(where_conditions)
    
    # æŸ¥è¯¢æ•°æ®
    query = f"SELECT * FROM investor_positions {where_clause} ORDER BY InvestorID, InstrumentID"
    positions = db_manager.execute_query(query, params)
    
    if not positions:
        return jsonify({'success': False, 'message': 'æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ•°æ®'})
    
    # åˆ›å»ºCSVæ–‡ä»¶
    output = io.StringIO()
    writer = csv.writer(output)
    
    # å†™å…¥è¡¨å¤´
    if positions:
        headers = list(positions[0].keys())
        writer.writerow(headers)
        
        # å†™å…¥æ•°æ®
        for position in positions:
            writer.writerow([position[key] for key in headers])
    
    # åˆ›å»ºå“åº”
    output.seek(0)
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f'positions_{timestamp}.csv'
    
    # åˆ›å»ºå“åº”å¯¹è±¡
    response = make_response(output.getvalue())
    response.headers['Content-Type'] = 'text/csv; charset=utf-8-sig'
    response.headers['Content-Disposition'] = f'attachment; filename={filename}'
    
    return response

@app.route('/api/position_stats')
def get_position_stats():
    """è·å–æŒä»“ç»Ÿè®¡ä¿¡æ¯"""
    query = """
        SELECT 
            COUNT(*) as total_positions,
            COUNT(DISTINCT InvestorID) as total_investors,
            COUNT(DISTINCT InstrumentID) as total_instruments,
            SUM(Position) as total_position,
            SUM(PositionProfit) as total_position_profit,
            SUM(UseMargin) as total_margin
        FROM investor_positions
        WHERE Position > 0
    """
    result = db_manager.execute_query(query)
    
    if result:
        return jsonify({'success': True, 'data': result[0]})
    else:
        return jsonify({'success': False, 'message': 'æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯'})

@app.route('/api/export/accounts')
def export_accounts_csv():
    """å¯¼å‡ºèµ„é‡‘è´¦æˆ·æ•°æ®ä¸ºCSV"""
    search = request.args.get('search', '', type=str)
    
    # æ„å»ºæŸ¥è¯¢æ¡ä»¶
    where_conditions = []
    params = []
    
    if search:
        where_conditions.append("(AccountID LIKE %s OR BrokerID LIKE %s)")
        search_param = f"%{search}%"
        params.extend([search_param, search_param])
    
    where_clause = ""
    if where_conditions:
        where_clause = "WHERE " + " AND ".join(where_conditions)
    
    # æŸ¥è¯¢æ•°æ®
    query = f"SELECT * FROM trading_account {where_clause} ORDER BY TradingDay DESC, AccountID"
    accounts = db_manager.execute_query(query, params)
    
    if not accounts:
        return jsonify({'success': False, 'message': 'æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ•°æ®'})
    
    # åˆ›å»ºCSVæ–‡ä»¶
    output = io.StringIO()
    writer = csv.writer(output)
    
    # å†™å…¥è¡¨å¤´
    if accounts:
        headers = list(accounts[0].keys())
        writer.writerow(headers)
        
        # å†™å…¥æ•°æ®
        for account in accounts:
            writer.writerow([account[key] for key in headers])
    
    # åˆ›å»ºå“åº”
    output.seek(0)
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f'accounts_{timestamp}.csv'
    
    # åˆ›å»ºå“åº”å¯¹è±¡
    response = make_response(output.getvalue())
    response.headers['Content-Type'] = 'text/csv; charset=utf-8-sig'
    response.headers['Content-Disposition'] = f'attachment; filename={filename}'
    
    return response

# ========== WebSocketç›¸å…³åŠŸèƒ½ ==========

def redis_listener():
    """Redisè®¢é˜…ç›‘å¬å™¨"""
    global market_running
    
    print("ğŸ§ å¯åŠ¨Redisè¡Œæƒ…ç›‘å¬å™¨...")
    
    try:
        pubsub = redis_client.pubsub()
        pubsub.subscribe('market_data')
        print("ğŸ“¡ å·²è®¢é˜…Redisé¢‘é“'market_data'")
        
        message_count = 0
        last_status_time = time.time()
        
        for message in pubsub.listen():
            if not market_running:
                print("ğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºRedisç›‘å¬å™¨")
                break
                
            if message['type'] == 'subscribe':
                print(f"âœ… æˆåŠŸè®¢é˜…Redisé¢‘é“: {message['channel']}")
                
            elif message['type'] == 'message':
                try:
                    message_count += 1
                    current_time = time.time()
                    
                    # è§£æè¡Œæƒ…æ•°æ®
                    market_data = json.loads(message['data'])
                    
                    # æ¯30ç§’æˆ–æ¯100æ¡æ¶ˆæ¯æ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†çŠ¶æ€
                    if (current_time - last_status_time > 30) or (message_count % 100 == 1):
                        print(f"ğŸ“Š çŠ¶æ€æŠ¥å‘Š [æ¶ˆæ¯{message_count}]:")
                        print(f"   å½“å‰è®¢é˜…å®¢æˆ·ç«¯: {list(market_subscribers)} (å…±{len(market_subscribers)}ä¸ª)")
                        print(f"   market_running: {market_running}")
                        print(f"   è¿æ¥æ€»æ•°: {connection_count}")
                        print(f"   å®¢æˆ·ç«¯è°ƒè¯•ä¿¡æ¯: {client_debug_info}")
                        last_status_time = current_time
                    
                    # æ›´æ–°æœ€æ–°è¡Œæƒ…æ•°æ®
                    latest_market_data[market_data['instrument_id']] = market_data
                    
                    if message_count % 50 == 1:
                        print(f"ğŸ“¨ [{message_count}] æ”¶åˆ°Redisæ¶ˆæ¯: {market_data.get('instrument_id', 'UNKNOWN')} - {market_data.get('last_price', 'N/A')}")
                        print(f"ğŸ“¦ å½“å‰å­˜å‚¨åˆçº¦æ•°: {len(latest_market_data)}")
                    
                except Exception as e:
                    print(f"âŒ å¤„ç†Redisæ¶ˆæ¯å¤±è´¥: {e}")
                    print(f"   æ¶ˆæ¯å†…å®¹: {message}")
                    
    except Exception as e:
        print(f"âŒ Redisç›‘å¬å™¨å¼‚å¸¸: {e}")
        traceback.print_exc()
    finally:
        print("ğŸ§ Redisç›‘å¬å™¨å·²åœæ­¢")

@socketio.on('connect')
def handle_connect():
    """å®¢æˆ·ç«¯è¿æ¥"""
    global connection_count
    connection_count += 1
    print(f"âœ… å®¢æˆ·ç«¯è¿æ¥: {request.sid} (è¿æ¥è®¡æ•°: {connection_count})")
    emit('connected', {'status': 'success', 'message': 'è¿æ¥æˆåŠŸ'})

@socketio.on('disconnect')
def handle_disconnect():
    """å®¢æˆ·ç«¯æ–­å¼€è¿æ¥"""
    global connection_count
    connection_count -= 1
    
    # æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦åœ¨è®¢é˜…åˆ—è¡¨ä¸­
    was_subscribed = request.sid in market_subscribers
    
    print(f"âŒ å®¢æˆ·ç«¯æ–­å¼€: {request.sid} (è¿æ¥è®¡æ•°: {connection_count})")
    print(f"   æ–­å¼€å‰æ˜¯å¦è®¢é˜…: {was_subscribed}")
    print(f"   æ–­å¼€å‰è®¢é˜…åˆ—è¡¨: {list(market_subscribers)} (å…±{len(market_subscribers)}ä¸ª)")
    
    market_subscribers.discard(request.sid)
    
    print(f"   æ–­å¼€åè®¢é˜…åˆ—è¡¨: {list(market_subscribers)} (å…±{len(market_subscribers)}ä¸ª)")
    
    # æ¸…ç†è°ƒè¯•ä¿¡æ¯
    if request.sid in client_debug_info:
        del client_debug_info[request.sid]

@socketio.on('subscribe_market')
def handle_subscribe_market():
    """è®¢é˜…è¡Œæƒ…æ•°æ®"""
    global market_thread, market_running
    
    print(f"ğŸ“¡ å®¢æˆ·ç«¯ {request.sid} è¯·æ±‚è®¢é˜…è¡Œæƒ…æ•°æ®")
    print(f"   è®¢é˜…å‰market_subscribers: {list(market_subscribers)} (å…±{len(market_subscribers)}ä¸ª)")
    
    # è®°å½•å®¢æˆ·ç«¯è°ƒè¯•ä¿¡æ¯
    client_debug_info[request.sid] = {
        'subscribe_time': time.time(),
        'connection_count': connection_count
    }
    
    # ç›´æ¥æ·»åŠ åˆ°è®¢é˜…åˆ—è¡¨ï¼ˆä¸ä½¿ç”¨roomæœºåˆ¶ï¼‰
    market_subscribers.add(request.sid)
    print(f"   å·²æ·»åŠ åˆ°market_subscribers")
    print(f"   è®¢é˜…åmarket_subscribers: {list(market_subscribers)} (å…±{len(market_subscribers)}ä¸ª)")
    
    # å¯åŠ¨Redisç›‘å¬çº¿ç¨‹ï¼ˆå¦‚æœè¿˜æœªå¯åŠ¨ï¼‰
    if not market_running:
        print("ğŸš€ å¯åŠ¨Redisç›‘å¬çº¿ç¨‹...")
        market_running = True
        market_thread = threading.Thread(target=redis_listener, daemon=True)
        market_thread.start()
        print(f"âœ… Redisç›‘å¬çº¿ç¨‹å·²å¯åŠ¨ï¼Œçº¿ç¨‹ID: {market_thread.ident}")
        print(f"   çº¿ç¨‹æ˜¯å¦æ´»è·ƒ: {market_thread.is_alive()}")
    else:
        print(f"â„¹ï¸  Redisç›‘å¬çº¿ç¨‹å·²åœ¨è¿è¡Œï¼Œçº¿ç¨‹ID: {market_thread.ident if market_thread else 'None'}")
        if market_thread:
            print(f"   çº¿ç¨‹æ˜¯å¦æ´»è·ƒ: {market_thread.is_alive()}")
    
    emit('subscription_success', {
        'status': 'success', 
        'message': 'è¡Œæƒ…è®¢é˜…æˆåŠŸ',
        'subscribers': len(market_subscribers)
    })
    print(f"âœ… å·²å‘é€è®¢é˜…æˆåŠŸå“åº”ç»™å®¢æˆ·ç«¯ {request.sid}")
    print(f"   å½“å‰å…¨å±€çŠ¶æ€: market_running={market_running}, è®¢é˜…å®¢æˆ·ç«¯æ•°={len(market_subscribers)}")
    
    # å‘é€æµ‹è¯•æ¶ˆæ¯éªŒè¯è¿æ¥
    emit('test_message', {
        'message': 'è¿™æ˜¯ä¸€æ¡æµ‹è¯•æ¶ˆæ¯',
        'timestamp': time.time(),
        'client_id': request.sid
    })
    print(f"ğŸ§ª å·²å‘é€æµ‹è¯•æ¶ˆæ¯ç»™å®¢æˆ·ç«¯ {request.sid}")
    
    # å¯åŠ¨å®šæ—¶å‘é€è¡Œæƒ…æ•°æ®
    if len(market_subscribers) == 1:  # ç¬¬ä¸€ä¸ªå®¢æˆ·ç«¯è®¢é˜…æ—¶å¯åŠ¨
        print("ğŸ•’ å¯åŠ¨å®šæ—¶å‘é€ä»»åŠ¡...")
        start_market_data_sender()


@socketio.on('unsubscribe_market')
def handle_unsubscribe_market():
    """å–æ¶ˆè®¢é˜…è¡Œæƒ…æ•°æ®"""
    print(f"ğŸ›‘ å®¢æˆ·ç«¯ {request.sid} è¯·æ±‚å–æ¶ˆè®¢é˜…è¡Œæƒ…æ•°æ®")
    print(f"   å–æ¶ˆå‰market_subscribers: {list(market_subscribers)} (å…±{len(market_subscribers)}ä¸ª)")
    
    # ä»è®¢é˜…åˆ—è¡¨ä¸­ç§»é™¤
    market_subscribers.discard(request.sid)
    print(f"   å·²ä»market_subscribersä¸­ç§»é™¤")
    print(f"   å–æ¶ˆåmarket_subscribers: {list(market_subscribers)} (å…±{len(market_subscribers)}ä¸ª)")
    
    # æ¸…ç†å®¢æˆ·ç«¯è°ƒè¯•ä¿¡æ¯
    if request.sid in client_debug_info:
        del client_debug_info[request.sid]
        print(f"   å·²æ¸…ç†å®¢æˆ·ç«¯è°ƒè¯•ä¿¡æ¯")
    
    # å‘é€å–æ¶ˆè®¢é˜…æˆåŠŸå“åº”
    emit('unsubscription_success', {
        'status': 'success', 
        'message': 'å·²å–æ¶ˆè¡Œæƒ…è®¢é˜…',
        'subscribers': len(market_subscribers)
    })
    print(f"âœ… å·²å‘é€å–æ¶ˆè®¢é˜…æˆåŠŸå“åº”ç»™å®¢æˆ·ç«¯ {request.sid}")
    print(f"   å½“å‰è®¢é˜…å®¢æˆ·ç«¯æ•°: {len(market_subscribers)}")


def start_market_data_sender():
    """å¯åŠ¨å®šæ—¶å‘é€è¡Œæƒ…æ•°æ®çš„ä»»åŠ¡"""
    @socketio.on('start_background_task')
    def handle_start_background_task():
        """å¯åŠ¨åå°ä»»åŠ¡"""
        print("ğŸ”„ å¯åŠ¨åå°å‘é€ä»»åŠ¡")
        
    def background_task():
        """åå°å‘é€ä»»åŠ¡"""
        print("ğŸš€ åå°ä»»åŠ¡å¯åŠ¨...")
        
        global send_batch_offset
        
        while market_running and market_subscribers:
            try:
                # å‘é€æœ€æ–°çš„è¡Œæƒ…æ•°æ®
                sent_count = 0
                
                if latest_market_data and market_subscribers:
                    # è·å–æ‰€æœ‰åˆçº¦æ•°æ®
                    all_items = list(latest_market_data.items())
                    total_contracts = len(all_items)
                    
                    if total_contracts > 0:
                        # æ¯æ¬¡å‘é€30ä¸ªåˆçº¦ï¼Œé‡‡ç”¨è½®æ¢ç­–ç•¥
                        batch_size = 30
                        
                        # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„èµ·å§‹å’Œç»“æŸä½ç½®
                        start_idx = send_batch_offset % total_contracts
                        end_idx = min(start_idx + batch_size, total_contracts)
                        
                        # å¦‚æœä¸å¤Ÿ30ä¸ªï¼Œä»å¤´å¼€å§‹è¡¥å……
                        if end_idx - start_idx < batch_size and total_contracts > batch_size:
                            # å–å½“å‰æ‰¹æ¬¡ + ä»å¤´å¼€å§‹çš„éƒ¨åˆ†
                            current_batch = all_items[start_idx:end_idx]
                            remaining_needed = batch_size - len(current_batch)
                            current_batch.extend(all_items[:remaining_needed])
                            send_items = current_batch
                        else:
                            send_items = all_items[start_idx:end_idx]
                        
                        # æ›´æ–°åç§»é‡ï¼Œä¸‹æ¬¡ä»ä¸åŒä½ç½®å¼€å§‹
                        send_batch_offset = (send_batch_offset + batch_size) % total_contracts
                        
                        for instrument_id, market_data in send_items:
                            for client_id in list(market_subscribers):
                                try:
                                    socketio.emit('market_data', market_data, room=client_id)
                                    sent_count += 1
                                except Exception as e:
                                    print(f"âŒ åå°å‘é€å¤±è´¥: {e}")
                                    market_subscribers.discard(client_id)
                        
                        if sent_count > 0:
                            print(f"ğŸ”„ åå°å‘é€: {sent_count} æ¡æ•°æ®ç»™ {len(market_subscribers)} ä¸ªå®¢æˆ·ç«¯")
                            print(f"   æœ¬æ‰¹æ¬¡åˆçº¦: {len(send_items)}ä¸ª (ç¬¬{start_idx+1}-{start_idx+len(send_items)}ä¸ª)")
                            print(f"   æ€»åˆçº¦æ•°: {total_contracts}ä¸ª, ä¸‹æ¬¡ä»ç¬¬{(send_batch_offset % total_contracts)+1}ä¸ªå¼€å§‹")
                
                # ç­‰å¾…2ç§’å†å‘é€ä¸‹ä¸€æ‰¹
                socketio.sleep(2)
                
            except Exception as e:
                print(f"âŒ åå°ä»»åŠ¡å¼‚å¸¸: {e}")
                break
                
        print("ğŸ”„ åå°ä»»åŠ¡ç»“æŸ")
    
    # å¯åŠ¨åå°ä»»åŠ¡
    socketio.start_background_task(background_task)
    print("âœ… SocketIOåå°å‘é€ä»»åŠ¡å·²å¯åŠ¨")


@socketio.on('get_market_status')
def handle_get_market_status():
    """è·å–è¡Œæƒ…æœåŠ¡çŠ¶æ€"""
    try:
        # è·å–Redisè¿æ¥çŠ¶æ€
        redis_status = redis_client.ping()
        
        emit('market_status', {
            'redis_connected': redis_status,
            'subscribers': len(market_subscribers),
            'thread_running': market_running,
            'thread_alive': market_thread.is_alive() if market_thread else False
        })
    except Exception as e:
        emit('market_status', {
            'error': str(e),
            'subscribers': len(market_subscribers)
        })

@socketio.on('trigger_manual_send')
def handle_trigger_manual_send():
    """æ‰‹åŠ¨è§¦å‘å‘é€æµ‹è¯•"""
    print(f"ğŸ”§ å®¢æˆ·ç«¯ {request.sid} è¯·æ±‚æ‰‹åŠ¨å‘é€æµ‹è¯•")
    
    # å‘é€æ‰‹åŠ¨è§¦å‘å“åº”
    emit('manual_trigger', {
        'message': 'æ‰‹åŠ¨è§¦å‘æµ‹è¯•',
        'timestamp': time.time(),
        'client_id': request.sid,
        'subscribers_count': len(market_subscribers)
    })
    
    # å¦‚æœæœ‰å­˜å‚¨çš„è¡Œæƒ…æ•°æ®ï¼Œå‘é€ä¸€æ¡
    if latest_market_data and market_subscribers:
        # å–ç¬¬ä¸€æ¡è¡Œæƒ…æ•°æ®
        sample_data = next(iter(latest_market_data.values()))
        emit('market_data', sample_data, room=request.sid)
        print(f"ğŸ”§ æ‰‹åŠ¨å‘é€äº†ä¸€æ¡è¡Œæƒ…æ•°æ®: {sample_data.get('instrument_id', 'UNKNOWN')}")
    else:
        print(f"ğŸ”§ æ²¡æœ‰å¯ç”¨çš„è¡Œæƒ…æ•°æ®æˆ–è®¢é˜…è€…")
    
    print(f"ğŸ”§ æ‰‹åŠ¨è§¦å‘å®Œæˆ")

# ========== å¥åº·æ£€æŸ¥API ==========

@app.route('/api/realtime/status')
def realtime_status():
    """å®æ—¶è¡Œæƒ…æœåŠ¡çŠ¶æ€"""
    try:
        redis_status = redis_client.ping()
        
        return jsonify({
            'status': 'success',
            'redis_connected': redis_status,
            'active_subscribers': len(market_subscribers),
            'market_listener_running': market_running,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/api/realtime/test')
def test_market_data():
    """å‘é€æµ‹è¯•è¡Œæƒ…æ•°æ®"""
    try:
        import random
        
        test_data = {
            'timestamp': datetime.now().isoformat(),
            'instrument_id': 'TEST001',
            'last_price': round(3000 + random.uniform(-10, 10), 2),
            'volume': random.randint(1000, 10000),
            'data_type': 'test_tick'
        }
        
        # å‘å¸ƒåˆ°Redis
        result = redis_client.publish('market_data', json.dumps(test_data))
        
        return jsonify({
            'status': 'success',
            'message': 'æµ‹è¯•æ•°æ®å·²å‘é€',
            'data': test_data,
            'subscribers_notified': result
        })
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500

def cleanup():
    """æ¸…ç†èµ„æº"""
    global market_running
    market_running = False
    print("ğŸ§¹ WebSocketåº”ç”¨æ¸…ç†å®Œæˆ")

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨æ”¯æŒWebSocketçš„CTPæŸ¥è¯¢ç³»ç»Ÿ...")
    print("è¯·ç¡®ä¿æ•°æ®åº“å’ŒRedisè¿æ¥æ­£å¸¸...")
    
    # æµ‹è¯•æ•°æ®åº“è¿æ¥
    if db_manager.connect():
        print("âœ“ æ•°æ®åº“è¿æ¥æˆåŠŸ")
    else:
        print("âœ— æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
    
    # æµ‹è¯•Redisè¿æ¥
    try:
        redis_client.ping()
        print("âœ“ Redisè¿æ¥æˆåŠŸ")
    except:
        print("âœ— Redisè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥RedisæœåŠ¡")
    
    print("å¯åŠ¨WebSocketæœåŠ¡å™¨...")
    print("è®¿é—®åœ°å€: http://localhost:5502")
    print("å®æ—¶è¡Œæƒ…: http://localhost:5502/realtime")
    print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    
    try:
        socketio.run(app, debug=False, host='0.0.0.0', port=5502)
    except KeyboardInterrupt:
        cleanup()
    except Exception as e:
        print(f"åº”ç”¨å¯åŠ¨å¤±è´¥: {e}")
        cleanup() 